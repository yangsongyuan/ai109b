## 0520第十三週
## 反傳遞演算法
反向傳播（英語：Backpropagation，縮寫為BP）是「誤差反向傳播」的簡稱，是一種與最優化方法（如梯度下降法）結合使用的，用來訓練人工神經網絡的常見方法。 該方法對網絡中所有權重計算損失函數的梯度。 這個梯度會反饋給最優化方法，用來更新權值以最小化損失函數。
[image](https://github.com/yangsongyuan/ai109b/blob/main/%E7%AD%86%E8%A8%98/%E5%8F%8D%E5%82%B3%E9%81%9E.png)
[維基百科](https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95)
## pytorch
* 自動求微分
* pip install torch 
    * 當出現強制結束 or killed時，就先第一檢查一下記憶體(大概率記憶體不足造成的)
* x.norm: x函數中的變數值相加平方開根號。
* torch.tensor: 單一數據類型元素的多维矩陣。
* x.grad: 該節點的梯度。
* f.backward: 求出函式f的反傳遞。
* x.item(): 從張量x中找出元素值
 net1.py程式碼
```
from net import Net
net = Net()

x = net.variable(1)
y = net.variable(3)
x2 = net.mul(x, x)
y2 = net.mul(y, y)
o  = net.add(x2, y2)

print('net.forward()=', net.forward())
print('net.backwward()')
net.backward()
print('x=', x, 'y=', y, 'o=', o)
print('gfx = x.g/o.g = ', x.g/o.g, 'gfy = y.g/o.g=', y.g/o.g)
```
結果
```
Jasonde-MacBook-Air:03-net jasonyang$ python3 net1.py
net.forward()= 10
net.backwward()
x= v:1 g:2 y= v:3 g:6 o= v:10 g:1
gfx = x.g/o.g =  2.0 gfy = y.g/o.g= 6.0
```
net2.py程式碼
```
from net import Net
net = Net()

x = net.variable(1)
y = net.variable(3)
x2 = net.mul(x, x)
y2 = net.mul(y, y)
o  = net.add(x2, y2)

net.gradient_descendent()
print('x=', x.v, 'y=', y.v)
```
結果
```
Jasonde-MacBook-Air:03-net jasonyang$ python3 net2.py
0  =>  10
1  =>  9.216
2  =>  8.4934656
3  =>  7.827577896960003
4  =>  7.213895789838339
5  =>  6.648326359915014
.
.
.
95  =>  0.004280892060076547
96  =>  0.003945270122566546
97  =>  0.003635960944957329
98  =>  0.003350901606872675
99  =>  0.003088190920893857
x= 0.01687031935884968 y= 0.050610958076549
```